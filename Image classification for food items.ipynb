{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPl6T876BS8jxEZmWjumVD9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":11,"metadata":{"id":"IEdhnxeTG7QD","executionInfo":{"status":"ok","timestamp":1698561407681,"user_tz":-330,"elapsed":612,"user":{"displayName":"Anshika Ranjan","userId":"14951409300736509682"}}},"outputs":[],"source":["import os\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report, confusion_matrix\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.preprocessing import image"]},{"cell_type":"code","source":["# configuring the path of Kaggle.json file\n","!mkdir -p ~/.kaggle\n","!cp kaggle.json ~/.kaggle/\n","!chmod 600 ~/.kaggle/kaggle.json"],"metadata":{"id":"VV_17ZZ_WJcg","executionInfo":{"status":"ok","timestamp":1698557330554,"user_tz":-330,"elapsed":601,"user":{"displayName":"Anshika Ranjan","userId":"14951409300736509682"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["!kaggle datasets download -d sainikhileshreddy/food-recognition-2022"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GIAVlGMLX-x-","executionInfo":{"status":"ok","timestamp":1698557392882,"user_tz":-330,"elapsed":60517,"user":{"displayName":"Anshika Ranjan","userId":"14951409300736509682"}},"outputId":"f1812053-0074-414e-faf4-1c1728135817"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading food-recognition-2022.zip to /content\n","100% 4.90G/4.91G [00:58<00:00, 106MB/s]\n","100% 4.91G/4.91G [00:58<00:00, 89.5MB/s]\n"]}]},{"cell_type":"code","source":["# extracting the compessed Dataset\n","from zipfile import ZipFile\n","dataset = '/content/food-recognition-2022.zip'\n","\n","with ZipFile(dataset,'r') as zip:\n","  zip.extractall()\n","  print('The dataset is extracted')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qXPS6QxmYBJ9","executionInfo":{"status":"ok","timestamp":1698557457887,"user_tz":-330,"elapsed":60891,"user":{"displayName":"Anshika Ranjan","userId":"14951409300736509682"}},"outputId":"1a286b6f-b132-44a2-ef40-064873ea4b68"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["The dataset is extracted\n"]}]},{"cell_type":"code","source":["# Change the path to the directory where your training data is stored\n","data_dir = '/content/raw_data/public_training_set_release_2.0'\n","\n","# Split your data into training and validation sets\n","train_datagen = ImageDataGenerator(\n","        rescale=1./255,\n","        rotation_range=20,\n","        width_shift_range=0.2,\n","        height_shift_range=0.2,\n","        horizontal_flip=True,\n","        fill_mode='nearest')\n","\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","train_generator = train_datagen.flow_from_directory(\n","        data_dir,\n","        target_size=(150, 150),\n","        batch_size=32,\n","        class_mode='categorical')\n","\n","validation_generator = test_datagen.flow_from_directory(\n","        data_dir,\n","        target_size=(150, 150),\n","        batch_size=32,\n","        class_mode='categorical')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vdCxb8FNYut2","executionInfo":{"status":"ok","timestamp":1698557516606,"user_tz":-330,"elapsed":1935,"user":{"displayName":"Anshika Ranjan","userId":"14951409300736509682"}},"outputId":"c58b7045-22ba-4889-a8ef-26f1ca770d82"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 39962 images belonging to 1 classes.\n","Found 39962 images belonging to 1 classes.\n"]}]},{"cell_type":"code","source":["# Define the CNN model architecture\n","model = Sequential()\n","model.add(Conv2D(32, (3, 3), input_shape=(150, 150, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Conv2D(32, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Conv2D(64, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Flatten())\n","model.add(Dense(64))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(1))\n","model.add(Activation('sigmoid'))\n","\n","# Compile the model\n","model.compile(loss='binary_crossentropy',\n","              optimizer='rmsprop',\n","              metrics=['accuracy'])"],"metadata":{"id":"qq2_vHrKZnZj","executionInfo":{"status":"ok","timestamp":1698557519907,"user_tz":-330,"elapsed":453,"user":{"displayName":"Anshika Ranjan","userId":"14951409300736509682"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Train the model\n","model.fit(\n","        train_generator,\n","        steps_per_epoch=8000 // 32,\n","        epochs=10,\n","        validation_data=validation_generator,\n","        validation_steps=2000 // 32)\n","\n","# Save the trained model\n","model.save('food_recognition_model.h5')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9cyedA2eZs53","executionInfo":{"status":"ok","timestamp":1698560802540,"user_tz":-330,"elapsed":1749367,"user":{"displayName":"Anshika Ranjan","userId":"14951409300736509682"}},"outputId":"48853822-4c15-4555-d7ed-a6c1c1e8a535"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","250/250 [==============================] - 307s 1s/step - loss: 0.0027 - accuracy: 0.9987 - val_loss: 2.8959e-07 - val_accuracy: 1.0000\n","Epoch 2/10\n","250/250 [==============================] - 301s 1s/step - loss: 5.1443e-07 - accuracy: 1.0000 - val_loss: 1.2288e-08 - val_accuracy: 1.0000\n","Epoch 3/10\n","250/250 [==============================] - 305s 1s/step - loss: 1.5136e-07 - accuracy: 1.0000 - val_loss: 2.8175e-09 - val_accuracy: 1.0000\n","Epoch 4/10\n","250/250 [==============================] - 290s 1s/step - loss: 3.1740e-06 - accuracy: 1.0000 - val_loss: 3.0120e-10 - val_accuracy: 1.0000\n","Epoch 5/10\n","250/250 [==============================] - 297s 1s/step - loss: 7.7718e-08 - accuracy: 1.0000 - val_loss: 1.2894e-10 - val_accuracy: 1.0000\n","Epoch 6/10\n","250/250 [==============================] - 316s 1s/step - loss: 9.7006e-08 - accuracy: 1.0000 - val_loss: 2.1375e-10 - val_accuracy: 1.0000\n","Epoch 7/10\n","250/250 [==============================] - 321s 1s/step - loss: 1.0827e-07 - accuracy: 1.0000 - val_loss: 1.4255e-10 - val_accuracy: 1.0000\n","Epoch 8/10\n","250/250 [==============================] - 295s 1s/step - loss: 7.4567e-08 - accuracy: 1.0000 - val_loss: 6.1458e-10 - val_accuracy: 1.0000\n","Epoch 9/10\n","250/250 [==============================] - 325s 1s/step - loss: 3.0871e-07 - accuracy: 1.0000 - val_loss: 2.0736e-10 - val_accuracy: 1.0000\n","Epoch 10/10\n","250/250 [==============================] - 294s 1s/step - loss: 6.3596e-08 - accuracy: 1.0000 - val_loss: 3.2324e-10 - val_accuracy: 1.0000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]}]},{"cell_type":"code","source":["# Load the trained model\n","model = load_model('food_recognition_model.h5')\n","\n","# Define the function to preprocess the image\n","def preprocess_image(img_path):\n","    img = image.load_img(img_path, target_size=(150, 150))\n","    img_array = image.img_to_array(img)\n","    img_array = np.expand_dims(img_array, axis=0)\n","    img_array /= 255.\n","    return img_array\n","\n","# Make a prediction for a given image\n","def predict_food(img_path):\n","    img_array = preprocess_image(img_path)\n","    predictions = model.predict(img_array)\n","    predicted_class = np.argmax(predictions)\n","    return predicted_class\n","\n","# Use the function to make a prediction\n","predicted_class = predict_food('/content/grain.jpg')\n","print(f'Predicted food class: {predicted_class}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A4zlECxkZ2O2","executionInfo":{"status":"ok","timestamp":1698562107798,"user_tz":-330,"elapsed":614,"user":{"displayName":"Anshika Ranjan","userId":"14951409300736509682"}},"outputId":"6bb7c5af-45a3-4420-ef46-26bd39c8ba7c"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 92ms/step\n","Predicted food class: 0\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"9rB2zBUYJV8V"},"execution_count":null,"outputs":[]}]}